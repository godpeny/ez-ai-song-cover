{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pyworld\n",
    "from huggingface_hub import hf_hub_download # downloading model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:22:15.280362Z",
     "start_time": "2023-08-19T04:22:14.838821Z"
    }
   },
   "id": "505f7021c020c950"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "mode = \"training\" \n",
    "MODEL_NAME = \"avc\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-19T04:22:17.360882Z",
     "start_time": "2023-08-19T04:22:17.358265Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!git submodule add https://github.com/godpeny/Retrieval-based-Voice-Conversion-WebUI.git\n",
    "!git submodule update --init --recursive\n",
    "!mkdir -p Retrieval-based-Voice-Conversion-WebUI/logs/{MODEL_NAME}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4291cfc67515e44f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Download pretrained model from huggingface hub\n",
    "REPO_ID = \"lj1995/VoiceConversionWebUI\"\n",
    "\n",
    "# for v1\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"pretrained/D32k.pth\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"pretrained/D40k.pth\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"pretrained/D48k.pth\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"pretrained/G32k.pth\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"pretrained/G40k.pth\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"pretrained/G48k.pth\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"pretrained/f0D32k.pth\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"pretrained/f0D40k.pth\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"pretrained/f0D48k.pth\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"pretrained/f0G32k.pth\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"pretrained/f0G40k.pth\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"pretrained/f0G48k.pth\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "\n",
    "# for v2\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"pretrained_v2/D40k.pth\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"pretrained_v2/G40k.pth\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"pretrained_v2/f0D40k.pth\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"pretrained_v2/f0G40k.pth\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "\n",
    "# hubert_base\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"hubert_base.pt\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)\n",
    "hf_hub_download(repo_id=REPO_ID, filename=\"rmvpe.pt\", local_dir=\"Retrieval-based-Voice-Conversion-WebUI\", local_dir_use_symlinks=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f594dff9f5e99f28"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI\n",
      "No supported Nvidia GPU found, use MPS instead\r\n",
      "Use Language: en_US\r\n",
      "Running on local URL:  http://0.0.0.0:7865\r\n",
      "python3.8 trainset_preprocess_pipeline_print.py \"../dataset/Always\" 40000 7 \"/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc\" False\r\n",
      "['trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "start preprocess\r\n",
      "['trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "['/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "['/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "['/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "['/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "['/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "['/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "['/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "../dataset/Always/split_4.wav->Suc.\r\n",
      "\u001B[0m../dataset/Always/split_2.wav->Suc.\r\n",
      "\u001B[0m../dataset/Always/split_1.wav->Suc.\r\n",
      "\u001B[0m../dataset/Always/split_0.wav->Suc.\r\n",
      "../dataset/Always/split_3.wav->Suc.\r\n",
      "\u001B[0m../dataset/Always/split_5.wav->Suc.\r\n",
      "\u001B[0m../dataset/Always/split_7.wav->Suc.\r\n",
      "\u001B[0m../dataset/Always/split_6.wav->Suc.\r\n",
      "\u001B[0mend preprocess\r\n",
      "\u001B[0m/opt/homebrew/Cellar/python@3.8/3.8.17/Frameworks/Python.framework/Versions/3.8/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 7 leaked semaphore objects to clean up at shutdown\r\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\r\n",
      "start preprocess\r\n",
      "['trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "../dataset/Always/split_4.wav->Suc.\r\n",
      "../dataset/Always/split_2.wav->Suc.\r\n",
      "../dataset/Always/split_1.wav->Suc.\r\n",
      "../dataset/Always/split_0.wav->Suc.\r\n",
      "../dataset/Always/split_3.wav->Suc.\r\n",
      "../dataset/Always/split_5.wav->Suc.\r\n",
      "../dataset/Always/split_7.wav->Suc.\r\n",
      "../dataset/Always/split_6.wav->Suc.\r\n",
      "end preprocess\r\n",
      "\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/godpeny/Code/venv/ai-voice-cover/lib/python3.8/site-packages/gradio/routes.py\", line 321, in run_predict\r\n",
      "    output = await app.blocks.process_api(\r\n",
      "  File \"/Users/godpeny/Code/venv/ai-voice-cover/lib/python3.8/site-packages/gradio/blocks.py\", line 1006, in process_api\r\n",
      "    result = await self.call_function(fn_index, inputs, iterator, request)\r\n",
      "  File \"/Users/godpeny/Code/venv/ai-voice-cover/lib/python3.8/site-packages/gradio/blocks.py\", line 847, in call_function\r\n",
      "    prediction = await anyio.to_thread.run_sync(\r\n",
      "  File \"/Users/godpeny/Code/venv/ai-voice-cover/lib/python3.8/site-packages/anyio/to_thread.py\", line 33, in run_sync\r\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\r\n",
      "  File \"/Users/godpeny/Code/venv/ai-voice-cover/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\r\n",
      "    return await future\r\n",
      "  File \"/Users/godpeny/Code/venv/ai-voice-cover/lib/python3.8/site-packages/anyio/_backends/_asyncio.py\", line 807, in run\r\n",
      "    result = context.run(func, *args)\r\n",
      "  File \"infer-web.py\", line 849, in click_train\r\n",
      "    & set([name.split(\".\")[0] for name in os.listdir(feature_dir)])\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/3_feature768'\r\n",
      "['trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "start preprocess\r\n",
      "['trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "['/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "['/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "['/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "['/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "['/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "['/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "['/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "../dataset/Always/split_1.wav->Suc.\r\n",
      "\u001B[0m../dataset/Always/split_4.wav->Suc.\r\n",
      "\u001B[0m../dataset/Always/split_2.wav->Suc.\r\n",
      "\u001B[0m../dataset/Always/split_0.wav->Suc.\r\n",
      "../dataset/Always/split_3.wav->Suc.\r\n",
      "\u001B[0m../dataset/Always/split_7.wav->Suc.\r\n",
      "\u001B[0m../dataset/Always/split_5.wav->Suc.\r\n",
      "\u001B[0m../dataset/Always/split_6.wav->Suc.\r\n",
      "\u001B[0mend preprocess\r\n",
      "\u001B[0mstart preprocess\r\n",
      "['trainset_preprocess_pipeline_print.py', '../dataset/Always', '40000', '7', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'False']\r\n",
      "../dataset/Always/split_1.wav->Suc.\r\n",
      "../dataset/Always/split_4.wav->Suc.\r\n",
      "../dataset/Always/split_2.wav->Suc.\r\n",
      "../dataset/Always/split_0.wav->Suc.\r\n",
      "../dataset/Always/split_3.wav->Suc.\r\n",
      "../dataset/Always/split_7.wav->Suc.\r\n",
      "../dataset/Always/split_5.wav->Suc.\r\n",
      "../dataset/Always/split_6.wav->Suc.\r\n",
      "end preprocess\r\n",
      "\r\n",
      "/opt/homebrew/Cellar/python@3.8/3.8.17/Frameworks/Python.framework/Versions/3.8/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 7 leaked semaphore objects to clean up at shutdown\r\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\r\n",
      "['extract_f0_print.py', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', '7', 'harvest']\r\n",
      "todo-f0-11\r\n",
      "f0ing,now-0,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_0.wav\r\n",
      "todo-f0-11\r\n",
      "f0ing,now-0,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_1.wav\r\n",
      "todo-f0-10\r\n",
      "f0ing,now-0,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_4.wav\r\n",
      "todo-f0-10\r\n",
      "f0ing,now-0,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_3.wav\r\n",
      "todo-f0-10\r\n",
      "f0ing,now-0,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_5.wav\r\n",
      "todo-f0-10\r\n",
      "f0ing,now-0,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_6.wav\r\n",
      "todo-f0-10\r\n",
      "f0ing,now-0,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_2.wav\r\n",
      "f0ing,now-2,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/2_2.wav\r\n",
      "f0ing,now-2,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/3_1.wav\r\n",
      "f0ing,now-2,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/3_2.wav\r\n",
      "f0ing,now-2,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/3_10.wav\r\n",
      "f0ing,now-2,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/2_3.wav\r\n",
      "f0ing,now-2,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/2_5.wav\r\n",
      "f0ing,now-2,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/3_0.wav\r\n",
      "f0ing,now-4,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/4_2.wav\r\n",
      "f0ing,now-4,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_10.wav\r\n",
      "f0ing,now-4,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/4_5.wav\r\n",
      "f0ing,now-4,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_1.wav\r\n",
      "f0ing,now-4,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_11.wav\r\n",
      "f0ing,now-4,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/4_3.wav\r\n",
      "f0ing,now-4,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_0.wav\r\n",
      "f0ing,now-6,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_8.wav\r\n",
      "f0ing,now-6,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_6.wav\r\n",
      "f0ing,now-6,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_1.wav\r\n",
      "f0ing,now-6,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_0.wav\r\n",
      "f0ing,now-6,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_7.wav\r\n",
      "f0ing,now-6,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_10.wav\r\n",
      "f0ing,now-6,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_9.wav\r\n",
      "f0ing,now-8,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_2.wav\r\n",
      "f0ing,now-8,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_18.wav\r\n",
      "f0ing,now-8,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_22.wav\r\n",
      "f0ing,now-8,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_21.wav\r\n",
      "f0ing,now-8,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_19.wav\r\n",
      "f0ing,now-8,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_24.wav\r\n",
      "f0ing,now-8,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_20.wav\r\n",
      "f0ing,now-10,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/7_0.wav\r\n",
      "f0ing,now-10,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/7_2.wav\r\n",
      "['extract_f0_print.py', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', '7', 'harvest']\r\n",
      "todo-f0-11\r\n",
      "f0ing,now-0,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_0.wav\r\n",
      "todo-f0-11\r\n",
      "f0ing,now-0,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_1.wav\r\n",
      "todo-f0-10\r\n",
      "f0ing,now-0,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_4.wav\r\n",
      "todo-f0-10\r\n",
      "f0ing,now-0,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_3.wav\r\n",
      "todo-f0-10\r\n",
      "f0ing,now-0,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_5.wav\r\n",
      "todo-f0-10\r\n",
      "f0ing,now-0,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_6.wav\r\n",
      "todo-f0-10\r\n",
      "f0ing,now-0,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_2.wav\r\n",
      "f0ing,now-2,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/2_2.wav\r\n",
      "f0ing,now-2,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/3_1.wav\r\n",
      "f0ing,now-2,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/3_2.wav\r\n",
      "f0ing,now-2,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/3_10.wav\r\n",
      "f0ing,now-2,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/2_3.wav\r\n",
      "f0ing,now-2,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/2_5.wav\r\n",
      "f0ing,now-2,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/3_0.wav\r\n",
      "f0ing,now-4,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/4_2.wav\r\n",
      "f0ing,now-4,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_10.wav\r\n",
      "f0ing,now-4,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/4_5.wav\r\n",
      "f0ing,now-4,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_1.wav\r\n",
      "f0ing,now-4,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_11.wav\r\n",
      "f0ing,now-4,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/4_3.wav\r\n",
      "f0ing,now-4,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_0.wav\r\n",
      "f0ing,now-6,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_8.wav\r\n",
      "f0ing,now-6,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_6.wav\r\n",
      "f0ing,now-6,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_1.wav\r\n",
      "f0ing,now-6,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_0.wav\r\n",
      "f0ing,now-6,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_7.wav\r\n",
      "f0ing,now-6,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_10.wav\r\n",
      "f0ing,now-6,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_9.wav\r\n",
      "f0ing,now-8,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_2.wav\r\n",
      "f0ing,now-8,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_18.wav\r\n",
      "f0ing,now-8,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_22.wav\r\n",
      "f0ing,now-8,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_21.wav\r\n",
      "f0ing,now-8,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_19.wav\r\n",
      "f0ing,now-8,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_24.wav\r\n",
      "f0ing,now-8,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_20.wav\r\n",
      "f0ing,now-10,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/7_0.wav\r\n",
      "f0ing,now-10,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/7_2.wav\r\n",
      "\r\n",
      "['extract_feature_print.py', 'mps', '1', '0', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'v2']\r\n",
      "/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc\r\n",
      "load model(s) from hubert_base.pt\r\n",
      "2023-08-19 13:24:43 | INFO | fairseq.tasks.hubert_pretraining | current directory is /Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI\r\n",
      "2023-08-19 13:24:43 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'metadata', 'fine_tuning': False, 'labels': ['km'], 'label_dir': 'label', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\r\n",
      "2023-08-19 13:24:43 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}\r\n",
      "move model to mps\r\n",
      "all-feature-72\r\n",
      "/Users/godpeny/Code/venv/ai-voice-cover/lib/python3.8/site-packages/torch/nn/utils/weight_norm.py:25: UserWarning: The operator 'aten::_weight_norm_interface' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/mps/MPSFallback.mm:11.)\r\n",
      "  return _weight_norm(v, g, self.dim)\r\n",
      "now-72,all-0,0_0.wav,(149, 768)\r\n",
      "now-72,all-7,0_8.wav,(62, 768)\r\n",
      "now-72,all-14,2_2.wav,(149, 768)\r\n",
      "now-72,all-21,3_3.wav,(149, 768)\r\n",
      "now-72,all-28,4_2.wav,(149, 768)\r\n",
      "now-72,all-35,5_12.wav,(149, 768)\r\n",
      "now-72,all-42,5_6.wav,(149, 768)\r\n",
      "now-72,all-49,6_11.wav,(149, 768)\r\n",
      "now-72,all-56,6_18.wav,(149, 768)\r\n",
      "now-72,all-63,6_3.wav,(149, 768)\r\n",
      "now-72,all-70,7_0.wav,(149, 768)\r\n",
      "all-feature-done\r\n",
      "['extract_f0_print.py', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', '7', 'harvest']\r\n",
      "todo-f0-11\r\n",
      "f0ing,now-0,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_0.wav\r\n",
      "todo-f0-11\r\n",
      "f0ing,now-0,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_1.wav\r\n",
      "todo-f0-10\r\n",
      "f0ing,now-0,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_4.wav\r\n",
      "todo-f0-10\r\n",
      "f0ing,now-0,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_3.wav\r\n",
      "todo-f0-10\r\n",
      "f0ing,now-0,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_5.wav\r\n",
      "todo-f0-10\r\n",
      "f0ing,now-0,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_6.wav\r\n",
      "todo-f0-10\r\n",
      "f0ing,now-0,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/0_2.wav\r\n",
      "f0ing,now-2,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/2_2.wav\r\n",
      "f0ing,now-2,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/3_1.wav\r\n",
      "f0ing,now-2,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/3_2.wav\r\n",
      "f0ing,now-2,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/3_10.wav\r\n",
      "f0ing,now-2,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/2_3.wav\r\n",
      "f0ing,now-2,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/2_5.wav\r\n",
      "f0ing,now-2,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/3_0.wav\r\n",
      "f0ing,now-4,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/4_2.wav\r\n",
      "f0ing,now-4,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_10.wav\r\n",
      "f0ing,now-4,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/4_5.wav\r\n",
      "f0ing,now-4,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_1.wav\r\n",
      "f0ing,now-4,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_11.wav\r\n",
      "f0ing,now-4,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/4_3.wav\r\n",
      "f0ing,now-4,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_0.wav\r\n",
      "f0ing,now-6,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_8.wav\r\n",
      "f0ing,now-6,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_6.wav\r\n",
      "f0ing,now-6,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_1.wav\r\n",
      "f0ing,now-6,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_0.wav\r\n",
      "f0ing,now-6,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_7.wav\r\n",
      "f0ing,now-6,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_10.wav\r\n",
      "f0ing,now-6,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/5_9.wav\r\n",
      "f0ing,now-8,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_2.wav\r\n",
      "f0ing,now-8,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_18.wav\r\n",
      "f0ing,now-8,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_22.wav\r\n",
      "f0ing,now-8,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_21.wav\r\n",
      "f0ing,now-8,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_19.wav\r\n",
      "f0ing,now-8,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_24.wav\r\n",
      "f0ing,now-8,all-10,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/6_20.wav\r\n",
      "f0ing,now-10,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/7_0.wav\r\n",
      "f0ing,now-10,all-11,-/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc/1_16k_wavs/7_2.wav\r\n",
      "['extract_feature_print.py', 'mps', '1', '0', '/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc', 'v2']\r\n",
      "/Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI/logs/avc\r\n",
      "load model(s) from hubert_base.pt\r\n",
      "move model to mps\r\n",
      "all-feature-72\r\n",
      "now-72,all-0,0_0.wav,(149, 768)\r\n",
      "now-72,all-7,0_8.wav,(62, 768)\r\n",
      "now-72,all-14,2_2.wav,(149, 768)\r\n",
      "now-72,all-21,3_3.wav,(149, 768)\r\n",
      "now-72,all-28,4_2.wav,(149, 768)\r\n",
      "now-72,all-35,5_12.wav,(149, 768)\r\n",
      "now-72,all-42,5_6.wav,(149, 768)\r\n",
      "now-72,all-49,6_11.wav,(149, 768)\r\n",
      "now-72,all-56,6_18.wav,(149, 768)\r\n",
      "now-72,all-63,6_3.wav,(149, 768)\r\n",
      "now-72,all-70,7_0.wav,(149, 768)\r\n",
      "all-feature-done\r\n",
      "\r\n",
      "INFO:avc:{'train': {'log_interval': 200, 'seed': 1234, 'epochs': 20000, 'learning_rate': 0.0001, 'betas': [0.8, 0.99], 'eps': 1e-09, 'batch_size': 1, 'fp16_run': False, 'lr_decay': 0.999875, 'segment_size': 12800, 'init_lr_ratio': 1, 'warmup_epochs': 0, 'c_mel': 45, 'c_kl': 1.0}, 'data': {'max_wav_value': 32768.0, 'sampling_rate': 40000, 'filter_length': 2048, 'hop_length': 400, 'win_length': 2048, 'n_mel_channels': 125, 'mel_fmin': 0.0, 'mel_fmax': None, 'training_files': './logs/avc/filelist.txt'}, 'model': {'inter_channels': 192, 'hidden_channels': 192, 'filter_channels': 768, 'n_heads': 2, 'n_layers': 6, 'kernel_size': 3, 'p_dropout': 0, 'resblock': '1', 'resblock_kernel_sizes': [3, 7, 11], 'resblock_dilation_sizes': [[1, 3, 5], [1, 3, 5], [1, 3, 5]], 'upsample_rates': [10, 10, 2, 2], 'upsample_initial_channel': 512, 'upsample_kernel_sizes': [16, 16, 4, 4], 'use_spectral_norm': False, 'gin_channels': 256, 'spk_embed_dim': 109}, 'model_dir': './logs/avc', 'experiment_dir': './logs/avc', 'save_every_epoch': 5, 'name': 'avc', 'total_epoch': 20, 'pretrainG': 'pretrained_v2/f0G40k.pth', 'pretrainD': 'pretrained_v2/f0D40k.pth', 'version': 'v2', 'gpus': '0', 'sample_rate': '40k', 'if_f0': 1, 'if_latest': 0, 'save_every_weights': '0', 'if_cache_data_in_gpu': 0}\r\n",
      "INFO:torch.distributed.distributed_c10d:Added key: store_based_barrier_key:1 to store for rank: 0\r\n",
      "INFO:torch.distributed.distributed_c10d:Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 1 nodes.\r\n",
      "gin_channels: 256 self.spk_embed_dim: 109\r\n",
      "INFO:avc:loaded pretrained pretrained_v2/f0G40k.pth\r\n",
      "<All keys matched successfully>\r\n",
      "INFO:avc:loaded pretrained pretrained_v2/f0D40k.pth\r\n",
      "<All keys matched successfully>\r\n",
      "/Users/godpeny/Code/venv/ai-voice-cover/lib/python3.8/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\r\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/SpectralOps.cpp:867.)\r\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\r\n",
      "/Users/godpeny/Code/venv/ai-voice-cover/lib/python3.8/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\r\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/SpectralOps.cpp:867.)\r\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\r\n",
      "/Users/godpeny/Code/venv/ai-voice-cover/lib/python3.8/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\r\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/SpectralOps.cpp:867.)\r\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\r\n",
      "/Users/godpeny/Code/venv/ai-voice-cover/lib/python3.8/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\r\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/SpectralOps.cpp:867.)\r\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\r\n",
      "/Users/godpeny/Code/venv/ai-voice-cover/lib/python3.8/site-packages/torch/functional.py:641: UserWarning: stft with return_complex=False is deprecated. In a future pytorch release, stft will return complex tensors for all inputs, and return_complex=False will raise an error.\r\n",
      "Note: you can still call torch.view_as_real on the complex output to recover the old return format. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/SpectralOps.cpp:867.)\r\n",
      "  return _VF.stft(input, n_fft, hop_length, win_length, window,  # type: ignore[attr-defined]\r\n",
      "INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\r\n",
      "/Users/godpeny/Code/venv/ai-voice-cover/lib/python3.8/site-packages/torch/autograd/__init__.py:200: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.\r\n",
      "grad.sizes() = [1, 21, 96], strides() = [57120, 96, 1]\r\n",
      "bucket_view.sizes() = [1, 21, 96], strides() = [2016, 96, 1] (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/distributed/c10d/reducer.cpp:337.)\r\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\r\n",
      "INFO:avc:Train Epoch: 1 [0%]\r\n",
      "INFO:avc:[0, 0.0001]\r\n",
      "INFO:avc:loss_disc=3.528, loss_gen=5.428, loss_fm=25.891,loss_mel=33.566, loss_kl=9.000\r\n",
      "DEBUG:matplotlib:matplotlib data path: /Users/godpeny/Code/venv/ai-voice-cover/lib/python3.8/site-packages/matplotlib/mpl-data\r\n",
      "DEBUG:matplotlib:CONFIGDIR=/Users/godpeny/.matplotlib\r\n",
      "DEBUG:matplotlib:interactive is False\r\n",
      "DEBUG:matplotlib:platform is darwin\r\n",
      "INFO:torch.nn.parallel.distributed:Reducer buckets have been rebuilt in this iteration.\r\n",
      "INFO:avc:====> Epoch: 1 [2023-08-19 13:26:37] | (0:01:45.683832)\r\n",
      "INFO:avc:====> Epoch: 2 [2023-08-19 13:28:16] | (0:01:38.493994)\r\n",
      "INFO:avc:Train Epoch: 3 [70%]\r\n",
      "INFO:avc:[200, 9.99750015625e-05]\r\n",
      "INFO:avc:loss_disc=3.554, loss_gen=3.520, loss_fm=28.714,loss_mel=33.897, loss_kl=2.802\r\n",
      "INFO:avc:====> Epoch: 3 [2023-08-19 13:29:54] | (0:01:38.390678)\r\n",
      "INFO:avc:====> Epoch: 4 [2023-08-19 13:31:32] | (0:01:37.143227)\r\n",
      "INFO:avc:Saving model and optimizer state at epoch 5 to ./logs/avc/G_370.pth\r\n",
      "INFO:avc:Saving model and optimizer state at epoch 5 to ./logs/avc/D_370.pth\r\n",
      "INFO:avc:====> Epoch: 5 [2023-08-19 13:33:10] | (0:01:38.259591)\r\n",
      "INFO:avc:Train Epoch: 6 [41%]\r\n",
      "INFO:avc:[400, 9.993751562304699e-05]\r\n",
      "INFO:avc:loss_disc=2.557, loss_gen=4.298, loss_fm=26.945,loss_mel=33.075, loss_kl=2.141\r\n",
      "INFO:avc:====> Epoch: 6 [2023-08-19 13:34:46] | (0:01:36.581895)\r\n",
      "INFO:avc:====> Epoch: 7 [2023-08-19 13:36:23] | (0:01:36.559386)\r\n",
      "INFO:avc:====> Epoch: 8 [2023-08-19 13:38:00] | (0:01:36.839013)\r\n",
      "INFO:avc:Train Epoch: 9 [11%]\r\n",
      "INFO:avc:[600, 9.990004373906418e-05]\r\n",
      "INFO:avc:loss_disc=3.987, loss_gen=3.237, loss_fm=23.757,loss_mel=29.928, loss_kl=3.156\r\n",
      "INFO:avc:====> Epoch: 9 [2023-08-19 13:39:39] | (0:01:39.217858)\r\n",
      "INFO:avc:Saving model and optimizer state at epoch 10 to ./logs/avc/G_740.pth\r\n",
      "INFO:avc:Saving model and optimizer state at epoch 10 to ./logs/avc/D_740.pth\r\n",
      "INFO:avc:====> Epoch: 10 [2023-08-19 13:41:19] | (0:01:40.020858)\r\n",
      "INFO:avc:Train Epoch: 11 [81%]\r\n",
      "INFO:avc:[800, 9.987507028906759e-05]\r\n",
      "INFO:avc:loss_disc=5.142, loss_gen=2.871, loss_fm=0.286,loss_mel=7.440, loss_kl=1.605\r\n",
      "INFO:avc:====> Epoch: 11 [2023-08-19 13:42:58] | (0:01:38.702513)\r\n",
      "INFO:avc:====> Epoch: 12 [2023-08-19 13:44:35] | (0:01:37.006167)\r\n",
      "INFO:avc:====> Epoch: 13 [2023-08-19 13:46:12] | (0:01:37.217809)\r\n",
      "INFO:avc:Train Epoch: 14 [51%]\r\n",
      "INFO:avc:[1000, 9.983762181915804e-05]\r\n",
      "INFO:avc:loss_disc=3.847, loss_gen=2.890, loss_fm=6.952,loss_mel=21.348, loss_kl=1.245\r\n",
      "INFO:avc:====> Epoch: 14 [2023-08-19 13:47:50] | (0:01:37.894040)\r\n",
      "INFO:avc:Saving model and optimizer state at epoch 15 to ./logs/avc/G_1110.pth\r\n",
      "INFO:avc:Saving model and optimizer state at epoch 15 to ./logs/avc/D_1110.pth\r\n",
      "INFO:avc:====> Epoch: 15 [2023-08-19 13:49:29] | (0:01:39.329679)\r\n",
      "INFO:avc:====> Epoch: 16 [2023-08-19 13:51:07] | (0:01:37.644463)\r\n",
      "INFO:avc:Train Epoch: 17 [22%]\r\n",
      "INFO:avc:[1200, 9.980018739066937e-05]\r\n",
      "INFO:avc:loss_disc=3.534, loss_gen=4.068, loss_fm=11.915,loss_mel=22.767, loss_kl=1.626\r\n",
      "INFO:avc:====> Epoch: 17 [2023-08-19 13:52:45] | (0:01:37.872479)\r\n",
      "INFO:avc:====> Epoch: 18 [2023-08-19 13:54:22] | (0:01:37.649687)\r\n",
      "INFO:avc:Train Epoch: 19 [92%]\r\n",
      "INFO:avc:[1400, 9.977523890319963e-05]\r\n",
      "INFO:avc:loss_disc=3.408, loss_gen=3.116, loss_fm=15.862,loss_mel=34.316, loss_kl=1.998\r\n",
      "INFO:avc:====> Epoch: 19 [2023-08-19 13:56:00] | (0:01:37.469820)\r\n",
      "INFO:avc:Saving model and optimizer state at epoch 20 to ./logs/avc/G_1480.pth\r\n",
      "INFO:avc:Saving model and optimizer state at epoch 20 to ./logs/avc/D_1480.pth\r\n",
      "INFO:avc:====> Epoch: 20 [2023-08-19 13:57:40] | (0:01:39.684925)\r\n",
      "INFO:avc:Training is done. The program is closed.\r\n",
      "INFO:avc:saving final ckpt:Success.\r\n",
      "\u001B[0m\u001B[0m\u001B[0m\u001B[0m\u001B[0m/opt/homebrew/Cellar/python@3.8/3.8.17/Frameworks/Python.framework/Versions/3.8/lib/python3.8/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 20 leaked semaphore objects to clean up at shutdown\r\n",
      "  warnings.warn('resource_tracker: There appear to be %d '\r\n",
      "loading weights/avc.pth\r\n",
      "gin_channels: 256 self.spk_embed_dim: 109\r\n",
      "<All keys matched successfully>\r\n",
      "2023-08-19 19:25:33 | INFO | fairseq.tasks.hubert_pretraining | current directory is /Users/godpeny/Code/src/github.com/godpeny/ai-voice-cover/Retrieval-based-Voice-Conversion-WebUI\r\n",
      "2023-08-19 19:25:33 | INFO | fairseq.tasks.hubert_pretraining | HubertPretrainingTask Config {'_name': 'hubert_pretraining', 'data': 'metadata', 'fine_tuning': False, 'labels': ['km'], 'label_dir': 'label', 'label_rate': 50.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 250000, 'min_sample_size': 32000, 'single_target': False, 'random_crop': True, 'pad_audio': False}\r\n",
      "2023-08-19 19:25:33 | INFO | fairseq.models.hubert.hubert | HubertModel Config: {'_name': 'hubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.1, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'encoder_layerdrop': 0.05, 'dropout_input': 0.1, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.1, 'mask_length': 10, 'mask_prob': 0.8, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 10, 'mask_channel_prob': 0.0, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False}\r\n"
     ]
    }
   ],
   "source": [
    "# Run RVC-Web\n",
    "%cd Retrieval-based-Voice-Conversion-WebUI\n",
    "!sh run.sh"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-08-19T04:22:20.777609Z"
    }
   },
   "id": "9f05c707ec2d6cbb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
